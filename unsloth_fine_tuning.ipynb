{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T22:18:11.426430Z",
     "start_time": "2025-10-17T22:18:10.684181Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_path = \"42bin_haber/news\"\n",
    "\n",
    "rows = []\n",
    "for category in os.listdir(base_path):\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        for file_name in os.listdir(category_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                file_path = os.path.join(category_path, file_name)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    text = f.read().strip()\n",
    "                    if len(text) > 30:  # Ã§ok kÄ±sa metinleri filtrele\n",
    "                        rows.append({\"kategori\": category, \"metin\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.head(), len(df))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  kategori                                              metin\n",
      "0  turkiye  KÄ±lÄ±Ã§daroÄŸlu'ndan Ã¶nemli aÃ§Ä±klama\\nCHP Genel B...\n",
      "1  turkiye  Ambulansa alÄ±nmayÄ±nca Ã¶ldÃ¼ mÃ¼?\\nAksaray'da kaz...\n",
      "2  turkiye  KaÃ§Ä±rÄ±lan kamu gÃ¶revlilerini alacak heyet yola...\n",
      "3  turkiye  Patriot'lar geldi, eylemler patladÄ±\\n \\n Alman...\n",
      "4  turkiye  Ä°zmir'de iÅŸkence maÄŸduruna yeniden AÄŸÄ±r Ceza y... 41988\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T22:18:17.269433Z",
     "start_time": "2025-10-17T22:18:16.661893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n"
   ],
   "id": "d860c26099cad6f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SametTurkmenoglu/.cache/pypoetry/virtualenvs/rag-bg-XTn4lRnm-py3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T22:18:31.926809Z",
     "start_time": "2025-10-17T22:18:21.681823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    max_seq_length=1024,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True # GPU belleÄŸini yarÄ± yarÄ±ya azaltÄ±r\n",
    ")"
   ],
   "id": "bf90743b2e24402f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "('unterminated string literal (detected at line 1122)', (1122, 1))\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.4: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Ti. Num GPUs = 1. Max memory: 15.585 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T22:18:37.632328Z",
     "start_time": "2025-10-17T22:18:35.326813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    # task_type=\"CAUSAL_LM\",  <-- kaldÄ±rÄ±ldÄ±\n",
    ")\n"
   ],
   "id": "6f8461fa647e5684",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.10.4 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-17T22:18:43.494920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer , DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"metin\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "train_data = train_data.map(tokenize, batched=True)\n",
    "test_data = test_data.map(tokenize, batched=True)\n",
    "\n",
    "def add_labels(example):\n",
    "    example[\"labels\"] = example[\"input_ids\"].copy()\n",
    "    return example\n",
    "\n",
    "train_data = train_data.map(add_labels)\n",
    "test_data = test_data.map(add_labels)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "cae5e99931c859a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37789/37789 [00:05<00:00, 6980.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4199/4199 [00:00<00:00, 7028.32 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37789/37789 [00:06<00:00, 5760.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4199/4199 [00:00<00:00, 5784.51 examples/s]\n",
      "/tmp/ipykernel_117489/3636975009.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 37,789 | Num Epochs = 3 | Total steps = 7,086\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 4,194,304 of 6,742,609,920 (0.06% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T10:45:30.715682Z",
     "start_time": "2025-10-19T10:45:28.240849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"DÄ±ÅŸiÅŸleri BakanÄ± DavutoÄŸlu, Yunanistan ile TÃ¼rkiye  ne dedi\"\n",
    "\n",
    "output = pipe(prompt,max_length=150,do_sample=True,temperature=0.8)\n",
    "print(output[0][\"generated_text\"])"
   ],
   "id": "a016eca84a7b6248",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÄ±ÅŸiÅŸleri BakanÄ± DavutoÄŸlu, Yunanistan ile TÃ¼rkiye  ne dedi?\n",
      "DÄ±ÅŸiÅŸleri BakanÄ± Ahmet DavutoÄŸlu, TÃ¼rkiye-Yunanistan iliÅŸkilerinin arttÄ±ÄŸÄ± gÃ¼nlerde Ã¶nemli bir geliÅŸme olduÄŸunu belirterek, Â“TÃ¼rkiye ve Yunanistan arasÄ±nda yeni bir dÃ¼nyasÄ±nÄ±n kurulmasÄ±nÄ±n ve geliÅŸmesinin ihtiyaÃ§ duyulduÄŸunuÂ” sÃ¶yledi.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T10:44:12.240386Z",
     "start_time": "2025-10-19T10:44:11.642901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"unsloth_llama_news\")\n",
    "tokenizer.save_pretrained(\"unsloth_llama_news\")"
   ],
   "id": "e6e7795a837d4cf9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unsloth_llama_news/tokenizer_config.json',\n",
       " 'unsloth_llama_news/special_tokens_map.json',\n",
       " 'unsloth_llama_news/chat_template.jinja',\n",
       " 'unsloth_llama_news/tokenizer.model',\n",
       " 'unsloth_llama_news/added_tokens.json',\n",
       " 'unsloth_llama_news/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
